{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üöÄ YOLO11 Shahed-136 Drone Detection\n**European Defense Hackathon Warsaw | Imperial College London SPQR**\n\n---\n\n### Setup Checklist:\n1. Enable GPU: `Runtime > Change runtime type > T4 GPU`\n2. Add secrets (üîë icon in left sidebar):\n   - `wandb` - your W&B API key\n   - `HF_TOKEN` - your HuggingFace token\n   - `roboflow` - your Roboflow API key\n3. Run all cells\n\n**Note:** Using YOLO11 (latest stable) - YOLO12 does not exist yet."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1Ô∏è‚É£ Install Dependencies\n",
    "!pip install -q ultralytics>=8.3.0 roboflow wandb huggingface_hub pyyaml pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2Ô∏è‚É£ Load Secrets & Login\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Load secrets from Colab\n",
    "WANDB_API_KEY = userdata.get('wandb')\n",
    "HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "ROBOFLOW_API_KEY = userdata.get('roboflow')  # Add this to your secrets!\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "\n",
    "# Login to services\n",
    "import wandb\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "from huggingface_hub import login as hf_login\n",
    "hf_login(token=HF_TOKEN)\n",
    "\n",
    "print(\"‚úÖ Logged in to W&B and HuggingFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3Ô∏è‚É£ Check GPU & Test YOLO11\nimport torch\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# Test YOLO11 (NOT YOLO12 - it doesn't exist!)\nfrom ultralytics import YOLO\ntest_model = YOLO(\"yolo11n.pt\")  # Downloads automatically\nprint(\"\\n‚úÖ YOLO11 loaded successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 4Ô∏è‚É£ Configuration\n\n# =============================================================================\n# EDIT THESE SETTINGS\n# =============================================================================\n\n# Model: yolo11n (fast/Pi-friendly) | yolo11s | yolo11m (balanced) | yolo11l | yolo11x (accurate)\n# For Raspberry Pi deployment, use yolo11n or yolo11s ONLY\nMODEL = \"yolo11n.pt\"  # Changed from yolo12m - use nano for Pi deployment!\n\n# Training\nEPOCHS = 100\nBATCH_SIZE = 16  # Reduce to 8 if OOM on Colab\nIMG_SIZE = 640\n\n# Dataset (Roboflow)\nWORKSPACE = \"shahed136\"\nPROJECT = \"shahed136-detect\"\nVERSION = 1\n\n# Logging\nWANDB_ENTITY = \"Imperial-College-London-SPQR\"\nWANDB_PROJECT = \"European-Defense-Hackathon-Warsaw\"\nHF_REPO = \"shng2025/EDTH-Warsaw-shahed136-detector\"\n\nprint(f\"\"\"\nConfiguration:\n  Model: {MODEL}\n  Epochs: {EPOCHS}\n  Batch: {BATCH_SIZE}\n  Image Size: {IMG_SIZE}\n  W&B: {WANDB_ENTITY}/{WANDB_PROJECT}\n  HuggingFace: {HF_REPO}\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5Ô∏è‚É£ Download Dataset\n",
    "from roboflow import Roboflow\n",
    "import yaml\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(WORKSPACE).project(PROJECT)\n",
    "version = project.version(VERSION)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n",
    "DATASET_PATH = dataset.location\n",
    "DATA_YAML = f\"{DATASET_PATH}/data.yaml\"\n",
    "\n",
    "# Get class names\n",
    "with open(DATA_YAML, 'r') as f:\n",
    "    data_info = yaml.safe_load(f)\n",
    "CLASS_NAMES = data_info.get(\"names\", [])\n",
    "if isinstance(CLASS_NAMES, dict):\n",
    "    CLASS_NAMES = [CLASS_NAMES[i] for i in sorted(CLASS_NAMES.keys())]\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset: {DATASET_PATH}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6Ô∏è‚É£ Setup Logging Classes\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class WandBLogger:\n",
    "    \"\"\"W&B logger with visual predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, run_name, config):\n",
    "        import wandb\n",
    "        self.wandb = wandb\n",
    "        self.run = wandb.init(\n",
    "            entity=WANDB_ENTITY,\n",
    "            project=WANDB_PROJECT,\n",
    "            name=run_name,\n",
    "            tags=[\"yolo12\", \"drone-detection\", \"shahed-136\", \"defense\"],\n",
    "            config=config,\n",
    "        )\n",
    "        self.run_id = self.run.id\n",
    "        print(f\"[W&B] {self.run.url}\")\n",
    "    \n",
    "    def log(self, metrics, step=None):\n",
    "        self.wandb.log(metrics, step=step)\n",
    "    \n",
    "    def log_predictions(self, model, images, class_names, epoch):\n",
    "        \"\"\"Log detection visualizations.\"\"\"\n",
    "        results = model.predict(images, conf=0.25, verbose=False)\n",
    "        wandb_images = []\n",
    "        \n",
    "        for img_path, result in zip(images, results):\n",
    "            img = Image.open(img_path)\n",
    "            boxes_data = []\n",
    "            \n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf = float(box.conf[0])\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    cls_name = class_names[cls_id] if cls_id < len(class_names) else str(cls_id)\n",
    "                    boxes_data.append({\n",
    "                        \"position\": {\n",
    "                            \"minX\": float(x1)/img.width, \"minY\": float(y1)/img.height,\n",
    "                            \"maxX\": float(x2)/img.width, \"maxY\": float(y2)/img.height,\n",
    "                        },\n",
    "                        \"class_id\": cls_id,\n",
    "                        \"box_caption\": f\"{cls_name}: {conf:.2f}\",\n",
    "                        \"scores\": {\"confidence\": conf},\n",
    "                    })\n",
    "            \n",
    "            wandb_images.append(self.wandb.Image(\n",
    "                img,\n",
    "                boxes={\"predictions\": {\n",
    "                    \"box_data\": boxes_data,\n",
    "                    \"class_labels\": {i: n for i, n in enumerate(class_names)},\n",
    "                }},\n",
    "                caption=f\"Epoch {epoch}\",\n",
    "            ))\n",
    "        \n",
    "        self.wandb.log({\"predictions/samples\": wandb_images}, step=epoch)\n",
    "    \n",
    "    def log_gt_vs_pred(self, model, img_paths, label_paths, class_names, epoch):\n",
    "        \"\"\"Log ground truth vs predictions.\"\"\"\n",
    "        images = []\n",
    "        for img_path, label_path in zip(img_paths, label_paths):\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "            \n",
    "            # Ground truth\n",
    "            gt_boxes = []\n",
    "            if Path(label_path).exists():\n",
    "                with open(label_path) as f:\n",
    "                    for line in f:\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            cls_id = int(parts[0])\n",
    "                            xc, yc, bw, bh = map(float, parts[1:5])\n",
    "                            gt_boxes.append({\n",
    "                                \"position\": {\"minX\": xc-bw/2, \"minY\": yc-bh/2, \"maxX\": xc+bw/2, \"maxY\": yc+bh/2},\n",
    "                                \"class_id\": cls_id,\n",
    "                                \"box_caption\": f\"GT: {class_names[cls_id] if cls_id < len(class_names) else cls_id}\",\n",
    "                            })\n",
    "            \n",
    "            # Predictions\n",
    "            result = model.predict(img_path, conf=0.25, verbose=False)[0]\n",
    "            pred_boxes = []\n",
    "            if result.boxes is not None:\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf = float(box.conf[0])\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    pred_boxes.append({\n",
    "                        \"position\": {\"minX\": x1/w, \"minY\": y1/h, \"maxX\": x2/w, \"maxY\": y2/h},\n",
    "                        \"class_id\": cls_id,\n",
    "                        \"box_caption\": f\"Pred: {class_names[cls_id] if cls_id < len(class_names) else cls_id} ({conf:.2f})\",\n",
    "                        \"scores\": {\"confidence\": conf},\n",
    "                    })\n",
    "            \n",
    "            labels = {i: n for i, n in enumerate(class_names)}\n",
    "            images.append(self.wandb.Image(img, boxes={\n",
    "                \"ground_truth\": {\"box_data\": gt_boxes, \"class_labels\": labels},\n",
    "                \"predictions\": {\"box_data\": pred_boxes, \"class_labels\": labels},\n",
    "            }))\n",
    "        \n",
    "        self.wandb.log({\"labeling_quality/comparison\": images}, step=epoch)\n",
    "    \n",
    "    def log_label_distribution(self, dataset_path, class_names):\n",
    "        \"\"\"Log class distribution.\"\"\"\n",
    "        counts = {}\n",
    "        for split in [\"train\", \"valid\", \"val\", \"test\"]:\n",
    "            labels_dir = Path(dataset_path) / split / \"labels\"\n",
    "            if not labels_dir.exists():\n",
    "                continue\n",
    "            for f in labels_dir.glob(\"*.txt\"):\n",
    "                for line in open(f):\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        cls_id = int(parts[0])\n",
    "                        name = class_names[cls_id] if cls_id < len(class_names) else str(cls_id)\n",
    "                        counts[name] = counts.get(name, 0) + 1\n",
    "        \n",
    "        table = self.wandb.Table(data=[[k, v] for k, v in counts.items()], columns=[\"class\", \"count\"])\n",
    "        self.wandb.log({\"dataset/label_distribution\": self.wandb.plot.bar(table, \"class\", \"count\", title=\"Labels\")})\n",
    "        print(f\"[W&B] Label counts: {counts}\")\n",
    "    \n",
    "    def finish(self):\n",
    "        self.wandb.finish()\n",
    "\n",
    "\n",
    "class HFCheckpointer:\n",
    "    \"\"\"HuggingFace Hub checkpointing.\"\"\"\n",
    "    \n",
    "    def __init__(self, run_name):\n",
    "        from huggingface_hub import HfApi, create_repo\n",
    "        self.api = HfApi()\n",
    "        self.run_name = run_name\n",
    "        self.run_folder = f\"runs/{run_name}\"\n",
    "        \n",
    "        try:\n",
    "            create_repo(HF_REPO, private=True, exist_ok=True, repo_type=\"model\")\n",
    "            print(f\"[HF] https://huggingface.co/{HF_REPO}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[HF] {e}\")\n",
    "    \n",
    "    def upload(self, model_path, epoch, metrics=None, is_best=False):\n",
    "        from huggingface_hub import upload_file\n",
    "        \n",
    "        if not Path(model_path).exists():\n",
    "            return\n",
    "        \n",
    "        filename = f\"{self.run_folder}/best.pt\" if is_best else f\"{self.run_folder}/epoch_{epoch:04d}.pt\"\n",
    "        \n",
    "        try:\n",
    "            upload_file(model_path, filename, HF_REPO, commit_message=f\"Epoch {epoch}\" + (\" (best)\" if is_best else \"\"))\n",
    "            print(f\"[HF] Uploaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[HF] Upload failed: {e}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Logging classes ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7Ô∏è‚É£ üöÄ Train YOLO12\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import SETTINGS\n",
    "\n",
    "SETTINGS[\"wandb\"] = True\n",
    "\n",
    "# Generate run name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = Path(MODEL).stem\n",
    "run_name = f\"{model_name}_{timestamp}\"\n",
    "print(f\"Run: {run_name}\")\n",
    "\n",
    "# Initialize loggers\n",
    "config = {\"model\": MODEL, \"epochs\": EPOCHS, \"batch\": BATCH_SIZE, \"img_size\": IMG_SIZE}\n",
    "wandb_logger = WandBLogger(run_name, config)\n",
    "hf_checkpointer = HFCheckpointer(run_name)\n",
    "\n",
    "# Log dataset stats\n",
    "wandb_logger.log_label_distribution(DATASET_PATH, CLASS_NAMES)\n",
    "\n",
    "# Get sample images for visualization\n",
    "val_dir = Path(DATASET_PATH) / \"valid\" / \"images\"\n",
    "if not val_dir.exists():\n",
    "    val_dir = Path(DATASET_PATH) / \"val\" / \"images\"\n",
    "\n",
    "sample_images = [str(p) for p in list(val_dir.glob(\"*.jpg\"))[:16]]\n",
    "\n",
    "# Get GT-pred pairs\n",
    "labels_dir = val_dir.parent / \"labels\"\n",
    "pairs = []\n",
    "for img in val_dir.glob(\"*\"):\n",
    "    if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        lbl = labels_dir / f\"{img.stem}.txt\"\n",
    "        if lbl.exists():\n",
    "            pairs.append((str(img), str(lbl)))\n",
    "pairs = pairs[:8]\n",
    "\n",
    "# Load model\n",
    "model = YOLO(MODEL)\n",
    "\n",
    "# Callbacks\n",
    "best_map = [0.0]\n",
    "\n",
    "def on_epoch_end(trainer):\n",
    "    epoch = trainer.epoch\n",
    "    metrics = trainer.metrics\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb_metrics = {\n",
    "        \"train/box_loss\": metrics.get(\"train/box_loss\", 0),\n",
    "        \"train/cls_loss\": metrics.get(\"train/cls_loss\", 0),\n",
    "        \"metrics/mAP50\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
    "        \"metrics/mAP50-95\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
    "        \"metrics/precision\": metrics.get(\"metrics/precision(B)\", 0),\n",
    "        \"metrics/recall\": metrics.get(\"metrics/recall(B)\", 0),\n",
    "    }\n",
    "    wandb_logger.log(wandb_metrics, step=epoch)\n",
    "    \n",
    "    # Visual predictions every 5 epochs\n",
    "    if epoch % 5 == 0 and sample_images:\n",
    "        wandb_logger.log_predictions(trainer.model, sample_images, CLASS_NAMES, epoch)\n",
    "        if pairs:\n",
    "            wandb_logger.log_gt_vs_pred(trainer.model, [p[0] for p in pairs], [p[1] for p in pairs], CLASS_NAMES, epoch)\n",
    "    \n",
    "    # HuggingFace checkpoints\n",
    "    current_map = metrics.get(\"metrics/mAP50(B)\", 0)\n",
    "    is_best = current_map > best_map[0]\n",
    "    if is_best:\n",
    "        best_map[0] = current_map\n",
    "    \n",
    "    if epoch % 10 == 0 or is_best:\n",
    "        save_dir = trainer.save_dir\n",
    "        last_pt = Path(save_dir) / \"weights\" / \"last.pt\"\n",
    "        best_pt = Path(save_dir) / \"weights\" / \"best.pt\"\n",
    "        \n",
    "        if last_pt.exists():\n",
    "            hf_checkpointer.upload(str(last_pt), epoch)\n",
    "        if is_best and best_pt.exists():\n",
    "            hf_checkpointer.upload(str(best_pt), epoch, is_best=True)\n",
    "\n",
    "model.add_callback(\"on_train_epoch_end\", on_epoch_end)\n",
    "\n",
    "# TRAIN!\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    patience=20,\n",
    "    \n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    augment=True,\n",
    "    mosaic=1.0,\n",
    "    \n",
    "    project=\"runs/detect\",\n",
    "    name=run_name,\n",
    "    exist_ok=True,\n",
    "    save_period=10,\n",
    "    \n",
    "    device=0,\n",
    "    workers=4,\n",
    "    amp=True,\n",
    "    \n",
    "    plots=True,\n",
    "    save=True,\n",
    "    val=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "wandb_logger.finish()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(f\"Results: runs/detect/{run_name}\")\n",
    "print(f\"Best weights: runs/detect/{run_name}/weights/best.pt\")\n",
    "print(f\"W&B: https://wandb.ai/{WANDB_ENTITY}/{WANDB_PROJECT}\")\n",
    "print(f\"HuggingFace: https://huggingface.co/{HF_REPO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 8Ô∏è‚É£ Final Validation\n",
    "val_metrics = model.val(data=DATA_YAML)\n",
    "\n",
    "print(f\"\\nüìä Final Results:\")\n",
    "print(f\"  mAP50:     {val_metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95:  {val_metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {val_metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall:    {val_metrics.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 9Ô∏è‚É£ Test on Image\n",
    "from google.colab import files\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# Upload test image\n",
    "print(\"Upload an image to test:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load best model\n",
    "best_model = YOLO(f\"runs/detect/{run_name}/weights/best.pt\")\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    results = best_model(filename, save=True)\n",
    "    print(f\"\\nDetections in {filename}:\")\n",
    "    for box in results[0].boxes:\n",
    "        cls_id = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        cls_name = CLASS_NAMES[cls_id] if cls_id < len(CLASS_NAMES) else str(cls_id)\n",
    "        print(f\"  - {cls_name}: {conf:.1%}\")\n",
    "    \n",
    "    # Show result\n",
    "    result_path = list(Path(\"runs/detect/predict\").glob(f\"*{Path(filename).stem}*\"))[0]\n",
    "    display(IPImage(filename=str(result_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üîü Download Model\n",
    "from google.colab import files\n",
    "\n",
    "# Download best weights\n",
    "files.download(f\"runs/detect/{run_name}/weights/best.pt\")\n",
    "\n",
    "# Optional: Export to ONNX and download\n",
    "# model.export(format=\"onnx\")\n",
    "# files.download(f\"runs/detect/{run_name}/weights/best.onnx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}